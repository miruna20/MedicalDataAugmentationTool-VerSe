import argparse
import pandas as pd
import os
import csv
import nibabel as nib
import SimpleITK as sitk
import random
#the purpose of this script is to be used in the inference step, between stage 2 and 3
#verifies if the landmarks generated by stage 2 contain any cervical vertebra, if yes the initial rai photos are cropped and the landmarks folder adjusted, if not the input is discarded


#method from payer in MedicalDataAugmentationTool/utils/io/text.py
def save_dict_csv(d, file_name, header=None):
    """
    Saves a dictionary as a .csv file. The key is written as the first column. If the value is a list or a tuple,
    each entry is written as a consecutive column. Otherwise, the value is written as the second column
    :param d: The dictionary to write
    :param file_name: The file name.
    :param header: If given, this list will be written as a header.
    """
    with open(file_name, 'w') as file:
        writer = csv.writer(file)
        if header is not None:
            writer.writerow(header)
        for key, value in sorted(d.items()):
            if isinstance(value, list):
                writer.writerow([key] + value)
            elif isinstance(value, tuple):
                writer.writerow([key] + list(value))
            else:
                writer.writerow([key, value])

def adapt_landmarks(landmarksFolder):
    landmarkLabels = os.path.join(landmarksFolder, "valid_landmarks.csv")
    landmarkCoords = os.path.join(landmarksFolder, "landmarks.csv")

    coord = pd.read_csv(landmarkCoords, sep=';', header=None)
    labels = pd.read_csv(landmarkLabels, sep=";", header=None)

    valid_labels_datasets = {}

    # create dictionary where keys are the names of the datasets and for each key the value is a list of the cervical labels in that dataset
    # overwrite it with this dictionary
    for index, row in labels.itertuples():
        found_cervical = False
        valid_labels_dataset = []
        splitted = row.split(',')
        for i in splitted:
            if i.isdecimal():
                label = int(i)
                if (label < 7):
                    valid_labels_dataset.append(label)
                    found_cervical = True

        if found_cervical:
            valid_labels_datasets[splitted[0]] = valid_labels_dataset
        else:
            labels.drop(index, inplace=True)


    valid_coord_datasets = {}
    coordinates_T2 = {}
    for index, row in coord.itertuples():
        valid_coord_dataset = []
        splitted = row.split(',')
        curr_dataset = splitted[0]
        if curr_dataset in valid_labels_datasets.keys():
            #coordinates needed for cropping if the certain dataset has Th2 included
            if (splitted[25] != "nan"):
                coordinates_T2[curr_dataset] = [float(splitted[25]), float(splitted[26]), float(splitted[27])]

            for i in range(1, 22):
                valid_coord_dataset.append(splitted[i])
            for i in range(22, len(splitted)):
                valid_coord_dataset.append("nan")

            valid_coord_datasets[curr_dataset] = valid_coord_dataset

    return valid_labels_datasets,valid_coord_datasets,coordinates_T2

def crop(image_path,coord):

    if not image_path.endswith(".nii.gz"):
        print("cannot crop files which are not in NifTi format")
        return

    print("cropping " + image_path)
    image = nib.load(image_path)

    reader = sitk.ImageFileReader()
    reader.SetFileName(image_path)
    reader.LoadPrivateTagsOn()
    reader.ReadImageInformation()

    resZ = image.header.get_zooms()[2]
    cropping_point = int(round(coord[2] / resZ))

    #crop exactly in the middle of T2
    nib.save(image.slicer[0:image.shape[0], 0:image.shape[1], cropping_point:image.shape[2]],image_path)

    return cropping_point


def adapt_coordinates(valid_landmarks_dataset,valid_coords_dataset,cropping_param):
    for label in valid_landmarks_dataset:
        valid_coords_dataset[3 * label + 2] = str(float(valid_coords_dataset[3 * label + 2])- cropping_param)
    return valid_coords_dataset


def adapt_images(imagesFolder, valid_labels_datasets, valid_coords_datasets,cropping_info):

    #iterate in the folder
    for image in os.listdir(imagesFolder):
        temp = image.replace("_",".") #this is for the _seg.nii.gz
        name_image = temp.split(".")[0]
        # if they have .nii.gz then verify if their name is to be found as key in the valid_labels_datasets
        if name_image in valid_labels_datasets.keys():
            print(name_image + " has cervical")
            # if yes and the TH2=8 is there
            if image.endswith(".nii.gz")  and name_image in cropping_info:
                print(name_image + " has TH2 so it will be cropped")

                #then crop and replace
                #save the 3 coordinates of Th2=label8
                coord_Th2 = cropping_info[name_image]

                cropping_point = crop(os.path.join(imagesFolder,image),coord_Th2)
                cropping_info[name_image] = cropping_point
                #adjust the coord[2] = z axis here directly according to the cropping number for each vertebra
                valid_coords_datasets[name_image] = adapt_coordinates(valid_labels_datasets[name_image],valid_coords_datasets[name_image],cropping_point)
            else:
                print(name_image + " does not have Th2 so it does not need to be cropped")
        else:
            # if the image does not contain cervical then remove it then just remove from the image folder
            os.remove(os.path.join(imagesFolder,image))
            print(image + "will be removed, does not have cervical")

    return valid_coords_datasets


if __name__ == '__main__':

    parser = argparse.ArgumentParser()

    #parse the console arguments
    parser.add_argument("--landmarksFolder", help="folder with the landmark labels and coordinates",required=True)
    parser.add_argument("--reorientedImagesFolder", help="folder with the rai oriented images")
    parser = parser.parse_args()

    landmarkLabels = os.path.join(parser.landmarksFolder, "valid_landmarks.csv")
    landmarkCoords = os.path.join(parser.landmarksFolder, "landmarks.csv")

    #first adapt the landmark folder
    valid_labels_datasets,valid_coord_datasets,cropping_info = adapt_landmarks(parser.landmarksFolder)

    #remove images if they do not have cervical
    #crop them if they do AND change the coordinates according to how much we cropped
    valid_coord_datasets = adapt_images(parser.reorientedImagesFolder,valid_labels_datasets,valid_coord_datasets, cropping_info)


    #after finishing save the labels accordingly
    save_dict_csv(valid_labels_datasets, landmarkLabels)
    save_dict_csv(valid_coord_datasets, landmarkCoords)

    #save also the coordinates for T2 for every dataset in order to be able to pad in the end
    save_dict_csv(cropping_info,os.path.join(parser.reorientedImagesFolder,"landmarks_T2.csv"))